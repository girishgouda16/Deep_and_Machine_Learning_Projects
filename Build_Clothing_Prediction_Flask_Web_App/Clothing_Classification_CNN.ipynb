{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lAqvSV-zFm19"
      },
      "source": [
        "### Clothing_Apparel_Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "colab_type": "code",
        "id": "NbjOWtxJFm2N",
        "outputId": "552d6023-d4de-4630-999b-67f6f858fb28"
      },
      "outputs": [],
      "source": [
        "#Import necessary Libraries\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# printing the version of tensorflow\n",
        "tensorflow.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "colab_type": "code",
        "id": "9tlPlQtdG1Ev",
        "outputId": "b385b12e-7ec1-42a3-c582-2d6b85854a33"
      },
      "outputs": [],
      "source": [
        "# Load fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "id": "qbs2QA6qFm26",
        "outputId": "be72fb98-843d-49db-85c4-8889e6f0bf3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples/observations in training data: 60000\n",
            "Number of labels in training data: 60000\n",
            "Dimensions of a single image in x_train:(28, 28)\n",
            "-------------------------------------------------------------\n",
            "Number of samples/observations in test data: 10000\n",
            "Number of labels in test data: 10000\n",
            "Dimensions of single image in x_test:(28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Explore the dataset\n",
        "# Check the shape and size of x_train, x_test, y_train, y_test\n",
        "print (\"Number of samples/observations in training data: \" + str(len(x_train)))\n",
        "print (\"Number of labels in training data: \" + str(len(y_train)))\n",
        "print (\"Dimensions of a single image in x_train:\" + str(x_train[0].shape))\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print (\"Number of samples/observations in test data: \" + str(len(x_test)))\n",
        "print (\"Number of labels in test data: \" + str(len(y_test)))\n",
        "print (\"Dimensions of single image in x_test:\" + str(x_test[0].shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hdXkB2axFm3N"
      },
      "source": [
        "### View sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "colab_type": "code",
        "id": "h7IrFmtbFm3Q",
        "outputId": "253204bc-a740-4d7b-d3c0-f7e6db913c16"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualization library to visualize images \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting 5 images, Subplot arugments represent nrows, ncols and index\n",
        "# Color map is set to grey since our image dataset is grayscale\n",
        "plt.subplot(231)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(232)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(233)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(234)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(235)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "\n",
        "# Visualize the images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kOiUxZ1Fm3f"
      },
      "source": [
        "### Let's create our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "YdCR3JawFm3k",
        "outputId": "41a5a6f6-41f9-490d-dc8b-c37b94713725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,200,778\n",
            "Trainable params: 1,200,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-11 11:48:11.366158: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
            "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-07-11 11:48:11.367173: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        }
      ],
      "source": [
        "#Import necessary keras specific libraries\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Setting Training Parameters like batch_size, epochs\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "# Storing the number of rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "''' Getting the data in the right 'shape' as required by Keras i.e. adding a 4th \n",
        "dimension to our data thereby changing the original image shape of (60000,28,28) \n",
        "to (60000,28,28,1)'''\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# Storing the shape of a single image \n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Changing image type to float32 data type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalizing the data by changing the image pixel range from (0 to 255) to (0 to 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Performing one hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Calculate the number of classes and number of pixels \n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qzoS-5OcFm3w"
      },
      "source": [
        "### Let's train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "bACuyHMEFm3y",
        "outputId": "52115174-f497-4ff2-c322-b4fc704d5833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "60000/60000 [==============================] - 852s 14ms/sample - loss: 1.5361 - accuracy: 0.4929 - val_loss: 0.8681 - val_accuracy: 0.6990\n",
            "Test loss: 0.8681096566200256\n",
            "Test accuracy: 0.699\n"
          ]
        }
      ],
      "source": [
        "model_fitting = model.fit(x_train, y_train,\n",
        "          batch_size=100,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "colab_type": "code",
        "id": "TKJkwl69HW9P",
        "outputId": "2cc2a8c2-56b0-446b-dad3-a44b24fc0e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145118 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.17-0ubuntu2~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.17-0ubuntu2~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.17-0ubuntu2~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ]
        }
      ],
      "source": [
        "# Configuration related preprocessing step before mounting the drive\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "id": "lE9aiDjmHy76",
        "outputId": "ed2d28fc-c3c5-4b65-ab7b-fe7e3990f856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3BDnAqerJc6s"
      },
      "outputs": [],
      "source": [
        "# Change the directory to current working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Youtube_Projects\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PmACEqXEYM96"
      },
      "outputs": [],
      "source": [
        "# Save the model with the name clothing_classification_model\n",
        "model.save('clothing_classification_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "colab_type": "code",
        "id": "5NQr-s4FUuJ7",
        "outputId": "c802ebbe-dd1a-4631-e849-c52d4a4a7c69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "Sandal\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import few more necessary libraries.\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Function to load and prepare the image in right shape\n",
        "def load_image(filename):\n",
        "\t# Load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# Convert the image to array\n",
        "\timg = img_to_array(img)\n",
        "\t# Reshape the image into a sample of 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# Prepare it as pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        "\n",
        "# Load an image and predict the apparel class\n",
        "img = load_image('sandal.jpg')\n",
        "# Load the saved model\n",
        "model = load_model('clothing_classification_model.h5')\n",
        "# Predict the apparel class\n",
        "class_prediction = model.predict_classes(img)\n",
        "print(class_prediction[0])\n",
        "\n",
        "#Map apparel category with the numerical class\n",
        "if class_prediction[0] == 0:\n",
        "  product = \"T-shirt/top\"\n",
        "elif class_prediction[0] == 1:\n",
        "  product = \"Trouser\"\n",
        "elif class_prediction[0] == 2:\n",
        "  product = \"Pullover\"\n",
        "elif class_prediction[0] == 3:\n",
        "  product = \"Dress\"\n",
        "elif class_prediction[0] == 4:\n",
        "  product = \"Coat\"\n",
        "elif class_prediction[0] == 5:\n",
        "  product = \"Sandal\"\n",
        "elif class_prediction[0] == 6:\n",
        "  product = \"Shirt\"\n",
        "elif class_prediction[0] == 7:\n",
        "  product = \"Sneaker\"\n",
        "elif class_prediction[0] == 8:\n",
        "  product = \"Bag\"\n",
        "else:\n",
        "  product = \"Ankle boot\"\n",
        "\n",
        "print(product)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pVSK19-OFm4m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I7X24nIDFm4v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Clothing_Classification_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "de9a4046344c40b3871eb8f61947381e748fe6a22e0034c92b645806e4ece2ed"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
